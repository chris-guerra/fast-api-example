{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency and async / await\n",
    "\n",
    "Modern versions of Python have support for \"asynchronous code\" using something called \"coroutines\", with **async** and **await** syntax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous code\n",
    "\n",
    "Asynchronous code is a way to tell your program that at some point in the code, it will have to wait for something else to finish somewhere else.\n",
    "\n",
    "The program will come back every time it has a chante because it's awaiting again, or whenever it finished all the work it had at that point. It will see if any of the tasks it was waiting for have already finished.\n",
    "\n",
    "Next, it takes the first task to finish and continues whatever it had to do with it. The \"wait for something.\n",
    "\n",
    "Then the program will come back every time it has a chance because it's waiting again, or whenever it finished all the work it had at that point. And it will see if any of the tasks it was waiting for have already finished, doing whatever it had to do.\n",
    "\n",
    "That \"wait for something else\" normally refers to I/O operations that are relatively \"slow\" (compared to the speed of the processor and the RAM memory), like waiting for:\n",
    "\n",
    "- the data from the client to be sent through the network\n",
    "- the data sent by your program to be received by the client through the network\n",
    "- the contents of a file in the disk to be read by the system and given to your program\n",
    "- the contents your program gave to the system to be written to disk\n",
    "- a remote API operation\n",
    "- a database operation to finish\n",
    "- a database query to return the results\n",
    "\n",
    "As the execution time is consumed mostly by waiting for I/O operations, they call them **\"I/O bound\"** operations.\n",
    "\n",
    "It's called **\"asynchronous\"** because the program doesn't have to be \"synchronized\" with the slow task, waiting for the exact moment that the task finishes, while doing nothing, to be able to take the task result and continue the work.\n",
    "\n",
    "Instead of that, by being an \"asynchronous\" system, once finished, the task can wait in line a little bit (some microseconds) for the program to finish whatever it went to do, and then come back to take the results and continue working with them.\n",
    "\n",
    "For \"synchronous\" (contrary to \"asynchronous\") they commonly also use the term \"sequential\", because the computer program follows all the steps in sequence before switching to a different task, even if those steps involve waiting.\n",
    "\n",
    "### Concurrency\n",
    "\n",
    "While a program or computer is at the line, it is just idle, waiting for it's turn, not doing anything very \"productive\". But the line is fast because the program is only taking the orders (not preparing them), so that's fine.\n",
    "\n",
    "Then, when it's the programs turn, you do actual \"productive\" work. But then, even though you still don't have your result, your work with the server is \"on pause\", because you have to wait response to be ready.\n",
    "\n",
    "But you can switch your attention and \"work\" on other tasks. Then you are again doing something very \"productive\". The other server / service says \"I'm finished with doing the task\" by putting your id on the counter's display, but you don't jump like crazy immediately when the displayed number changes to your turn number. You wait for your current task to finish and communicate that you are goint to the task.\n",
    "\n",
    "Then you go to the task, do the action, and return your response. That finishes that step / task of interaction with the server / other program. That in turn, creates a new task, but the previous one is finished.\n",
    "\n",
    "### Parallel Taks / Synchronous work\n",
    "\n",
    "**\"Synchronous\" work** requires to wait and be there at the exact moment the other service finishes it's task. Then you just perform the task and are done. This in an example would mean you are a program with two procesors, both waiting and dedicating their attention to the external task.\n",
    "\n",
    "The server has 8 processors. While the concurrent task might have only 2. But still, the final experience is not the best. In this scenario it makes a lot more sense to have a concurrent system. This is the case for most of the web applications. This \"waiting\" üïô is measured in microseconds, but still, summing it all, it's a lot of waiting in the end.\n",
    "\n",
    "That's why it makes a lot of sense to use asynchronous code for web APIs.\n",
    "\n",
    "**Is concurrency better than parallelism?**\n",
    "\n",
    "Nope! Concurrency is different than parallelism. And it is better on specific scenarios that involve a lot of waiting. Because of that, it generally is a lot better than parallelism for web application development. But not for everything.\n",
    "\n",
    "So, to balance that out, imagine the following short story:\n",
    "\n",
    "You have to clean a big, dirty house. There's no waiting anywhere, just a lot of work to be done, on multiple places of the house. You could have turns as in the burgers example, first the living room, then the kitchen, but as you are not waiting for anything, just cleaning and cleaning, the turns wouldn't affect anything.\n",
    "\n",
    "It would take the same amount of time to finish with or without turns (concurrency) and you would have done the same amount of work. But in this case, if you could bring the 8 ex-cashier/cooks/now-cleaners, and each one of them (plus you) could take a zone of the house to clean it, you could do all the work in parallel, with the extra help, and finish much sooner.\n",
    "\n",
    "In this scenario, each one of the cleaners (including you) would be a processor, doing their part of the job. And as most of the execution time is taken by actual work (instead of waiting), and the work in a computer is done by a CPU, they call these problems \"CPU bound\".\n",
    "\n",
    "Common examples of CPU bound operations are things that require complex math processing.\n",
    "\n",
    "- **Audio** or **image processing**.\n",
    "- **Computer vision:** an image is composed of millions of pixels, each pixel has 3 values / colors, processing that normally requires computing something on those pixels, all at the same time.\n",
    "- **Machine Learning:** it normally requires lots of \"matrix\" and \"vector\" multiplications. Think of a huge spreadsheet with numbers and multiplying all of them together at the same time.\n",
    "- **Deep Learning:** this is a sub-field of Machine Learning, so, the same applies. It's just that there is not a single spreadsheet of numbers to multiply, but a huge set of them, and in many cases, you use a special processor to build and / or use those models.\n",
    "\n",
    "### Concurrency + Parallelism: Web + Machine Learning\n",
    "\n",
    "With FastAPI you can take the advantage of concurrency but you can also exploit the benefits of parallelism and multiprocessing for CPU bound workloads like those in Machine Learning systems.\n",
    "\n",
    "That, plus the simple fact that Python is the main language for Data Science, Machine Learning and especially Deep Learning, make FastAPI a very good match for Data Science / Machine Learning web APIs and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## async and await\n",
    "\n",
    "Modern versions of Python have a very intuitive way to define asynchronous code. This makes it look just like normal \"sequential\" code and do the \"awaiting\" for you at the right moments.\n",
    "\n",
    "The key here is the await. It tells Python that it has to wait for your function to finish doing its thing before storing the results in the function. With that, Python will know that it can go and do something else in the meanwhile (like receiving another request).\n",
    "\n",
    "For await to work, it has to be inside a function that supports this asynchronicity. To do that, you just declare it with async def:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_burgers(number: int):\n",
    "    # Do some asynchronous stuff to create the burgers\n",
    "    return burgers\n",
    "\n",
    "burgers = await get_burgers(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With async def, Python knows that, inside that function, it has to be aware of await expressions, and that it can \"pause\" ‚è∏ the execution of that function and go do something else üîÄ before coming back.\n",
    "\n",
    "When you want to call an async def function, you have to \"await\" it. So, this won't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't work, because get_burgers was defined with: async def\n",
    "burgers = get_burgers(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if you are using a library that tells you that you can call it with await, you need to create the path operation functions that uses it with async def, like in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get('/burgers')\n",
    "async def read_burgers():\n",
    "    burgers = await get_burgers(2)\n",
    "    return burgers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More technical details\n",
    "\n",
    "You might have noticed that await can only be used inside of functions defined with async def. But at the same time, functions defined with async def have to be \"awaited\". So, functions with async def can only be called inside of functions defined with async def too.\n",
    "\n",
    "So, about the egg and the chicken, how do you call the first async function? If you are working with FastAPI you don't have to worry about that, because that \"first\" function will be your path operation function, and FastAPI will know how to do the right thing.\n",
    "\n",
    "But if you want to use async / await without FastAPI, you can do it as well.\n",
    "\n",
    "### Write your own async code¬∂\n",
    "Starlette (and FastAPI) are based on [AnyIO](https://anyio.readthedocs.io/en/stable/), which makes it compatible with both Python's standard library [asyncio](https://docs.python.org/3/library/asyncio-task.html) and [Trio](https://trio.readthedocs.io/en/stable/).\n",
    "\n",
    "In particular, you can directly use AnyIO for your advanced concurrency use cases that require more advanced patterns in your own code.\n",
    "\n",
    "And even if you were not using FastAPI, you could also write your own async applications with AnyIO to be highly compatible and get its benefits (e.g. structured concurrency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coroutines\n",
    "\n",
    "Coroutine is just the very fancy term for the thing returned by an **async def** function. Python knows that it is something like a function that it can start and that it will end at some point, but that it might be paused internally too, whenever there is an await inside of it.\n",
    "\n",
    "But all this functionality of using asynchronous code with async and await is many times summarized as using \"coroutines\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Technical Details\n",
    "\n",
    "### Path operation functions\n",
    "\n",
    "When you declare a path operation function with normal def instead of async def, it is run in an external threadpool that is then awaited, instead of being called directly (as it would block the server).\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "The same applies for dependencies. If a dependency is a standard def function instead of async def, it is run in the external threadpool.\n",
    "\n",
    "Sub-dependencies¬∂\n",
    "You can have multiple dependencies and sub-dependencies requiring each other (as parameters of the function definitions), some of them might be created with async def and some with normal def. It would still work, and the ones created with normal def would be called on an external thread (from the threadpool) instead of being \"awaited\".\n",
    "\n",
    "Other utility functions¬∂\n",
    "Any other utility function that you call directly can be created with normal def or async def and FastAPI won't affect the way you call it.\n",
    "\n",
    "This is in contrast to the functions that FastAPI calls for you: path operation functions and dependencies.\n",
    "\n",
    "If your utility function is a normal function with def, it will be called directly (as you write it in your code), not in a threadpool, if the function is created with async def then you should await for that function when you call it in your code."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
